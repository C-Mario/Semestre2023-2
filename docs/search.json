[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Semestre 2023-2",
    "section": "",
    "text": "Portada\nAquí se alojara todo lo correspondiente al semestre 2023-2 cursado en la Universidad Nacional de Colombia.\nEn la imagen de portada: Manami de Yowamushi pedal.\n\n\n\n\n Volver arriba"
  },
  {
    "objectID": "capitulos/series1.html",
    "href": "capitulos/series1.html",
    "title": "1  Introducción",
    "section": "",
    "text": "esto es series de tiempo!\n\n\n\n Volver arriba"
  },
  {
    "objectID": "capitulos/nopara1.html#estimación-histograma-de-la-densidad",
    "href": "capitulos/nopara1.html#estimación-histograma-de-la-densidad",
    "title": "2  Capítulo 1 del curso",
    "section": "Estimación histograma de la densidad",
    "text": "Estimación histograma de la densidad\nLa idea es que una variable aleatoria tiene un proceso o función de densidad subyacente la cuál genera los datos que tendremos finalmente a disposición. Dada una variable aleatoria \\(X\\), entonces \\(X \\sim f\\left(x;\\theta\\right)\\). En el caso paramétrico la estimación de la función de densidad estaría dada por \\(\\hat f \\left(x;\\theta\\right) = f\\left(x;\\hat{\\theta}\\right)\\) asumiendo que la población de la cuál provienen los datos sigue una distribución conocida con función de densidad \\(f\\).\nEn el caso no paramétrico, no se hace supuesto alguno sobre la función de densidad asociada a la población de la cuál provienen los datos. La estimación de la función de densidad puede hacerse por diferentes métodos, entre ellos los siguientes:\n\nHistograma\nPolígono de frecuencias\nNúcleo (kernel)\n\nEl primer enfonque es realizar la estimación de la función de densidad usando la estimación histograma de la densidad. Por ejemplo, si se tienen 100 datos cuyo histograma de frecuencias absolutas está dado por:\n\n\nCódigo\nx &lt;- rnorm(100, 0, 1)\nhist(x, freq=TRUE, col = \"#42A5F5\")\n\n\n\n\n\nLa estimación histograma de la densidad dados estos 100 datos es el siguiente:\n\n\nCódigo\nhist(x, freq=FALSE, col = \"#42A5F5\")\n\n\n\n\n\nPara realizar la estimación se tiene en cuenta lo siguiente:\n\n\\(f\\left(x\\right)\\) es la función de densidad asociada a la variable aleatoria \\(X\\)\n\\(\\hat{f}\\left(x\\right)\\) es la estimación de la función de densidad\n\\(\\hat f_H \\left(x\\right)\\) es la estimación histograma de la función de densidad\nEl área de cada rectángulo del histograma se denota por \\(f_j\\) y depende del número de datos cuyo valor cae en el dicho intervalo y del número total de datos, de tal manera que \\(f_j = \\frac{n_j}{n}\\)\nEl área de cada rectángulo también puede verse en términos de la estimación histograma y de la amplitud del intervalo. \\(\\hat{f}_H \\left(x\\right) \\times 2b\\) donde \\(b\\) es un valor a la derecha y a la izquierda del centro del intervalo.\n\nAsí, se tiene que si la amplitud del intervalo es \\(2b\\), entonces:\n\\[\\frac{n_j}{n} = 2b \\hat{f}_H \\left(x\\right)\\] \\[\\hat{f}_H \\left(x\\right)=\\frac{n_j}{2nb} \\hspace{0.5cm} \\textrm{donde} \\hspace{0.5cm} n_j=\\sum_{i=1}^n \\mathbf{I}_{\\left[x-b, x+b\\right]} \\left(x_i\\right)\\] Ahora, según \\(n_j\\) se tiene que:\n\\[\n\\begin{align}\nx-b \\leq x_i \\leq x+&b\\\\\n-b \\leq x_i-x \\leq &b\\\\\n-1 \\leq \\frac{x_i-x}{b} \\leq 1\n\\end{align}\n\\] y por lo tanto\n\\[n_j = \\sum_{i=1}^n \\mathbf{I}_{\\left[-1,1\\right]}\\left(\\frac{x_i-x}{b}\\right)\\]\nluego, la estimación histograma de la densidad puede escribirse como:\n\\[\\hat{f}_H \\left(x\\right) = \\frac{1}{nb} \\sum_{i=1}^n \\frac{1}{2} \\mathbf{I}_{\\left[-1,1\\right]}\\left(\\frac{x_i-x}{b}\\right) = \\frac{1}{nb} \\sum_{i=1}^n K_U\\left(u\\right)\\] donde\n\\[u = \\left(\\frac{x_i-x}{b}\\right) \\hspace{0.5cm} \\mathrm{y} \\hspace{0.5cm} K_U\\left(u\\right) = \\begin{cases}\\frac{1}{2} & -1&lt;u&lt;1 \\\\ 0 & \\text { e.o.c }\\end{cases}\\] \\(K_U\\) es un kernel uniforme. Es decir, es una función de densidad centrada en \\(0\\) y toma valores de la forma \\(u\\) entre \\(-1\\) y \\(1\\).\nSi ahora se supone que la amplitud del intervalo es \\(b\\), entonces se tiene que:\n\\[\\frac{n_j}{n} = b\\hat{f}_H \\left(x\\right)\\] \\[\\hat{f}_H \\left(x\\right)=\\frac{n_j}{nb} \\hspace{0.5cm} \\textrm{donde} \\hspace{0.5cm} n_j=\\sum_{i=1}^n \\mathbf{I}_{\\left[x-\\frac{b}{2}, x+\\frac{b}{2}\\right]} \\left(x_i\\right)\\] de \\(n_j\\) se tiene que\n\\[\n\\begin{align}\nx-\\frac{b}{2} \\leq x_i \\leq x+&\\frac{b}{2}\\\\\n-\\frac{b}{2} \\leq x_i-x \\leq &\\frac{b}{2}\\\\\n-\\frac{1}{2} \\leq \\frac{x_i-x}{b} \\leq &\\frac{1}{2}\n\\end{align}\n\\] y por lo tanto:\n\\[\\hat{f}_H \\left(x\\right)=\\frac{1}{nb} \\sum_{i=1}^n \\mathbf{I}_{\\left[-\\frac{1}{2},\\frac{1}{2}\\right]}\\left(\\frac{x_i-x}{b}\\right)=\\frac{1}{nb}K_U\\left(u\\right)\\] donde\n\\[u = \\left(\\frac{x_i-x}{b}\\right) \\hspace{0.5cm} \\mathrm{y} \\hspace{0.5cm} K_U\\left(u\\right) = \\begin{cases} 1 & -\\frac{1}{2}&lt;u&lt;\\frac{1}{2} \\\\ 0 & \\text { e.o.c }\\end{cases}\\] en forma general, si la amplitud del intervalo es \\(ab\\) entonces:\n\\[\\hat{f}_H \\left(x\\right)=\\frac{1}{nb} \\sum_{i=1}^n \\frac{1}{a} \\mathbf{I}_{\\left[-\\frac{ab}{2},\\frac{ab}{2}\\right]}\\left(\\frac{x_i-x}{b}\\right)=\\frac{1}{nb}K_U\\left(u\\right)\\] donde\n\\[u = \\left(\\frac{x_i-x}{b}\\right) \\hspace{0.5cm} \\mathrm{y} \\hspace{0.5cm} K_U\\left(u\\right) = \\begin{cases} \\frac{1}{a} & -\\frac{ab}{2}&lt;u&lt;\\frac{ab}{2} \\\\ 0 & \\text { e.o.c }\\end{cases}\\]"
  },
  {
    "objectID": "capitulos/nopara1.html#propiedades-del-estimador-histograma",
    "href": "capitulos/nopara1.html#propiedades-del-estimador-histograma",
    "title": "2  Capítulo 1 del curso",
    "section": "Propiedades del estimador histograma",
    "text": "Propiedades del estimador histograma\nDado que el estimador histograma de la densidad depende de la amplitud \\(b\\) del intervalo, la idea es escoger el valor de la amplitud que minimice el \\(\\textrm{MSE}\\) para así poder encontrar una estimación más exacta de la función de densidad subyacente a la población en cuestión.\n\\[\\begin{align}\n\\textrm{Var}\\left[\\hat b - b\\right] &= \\textrm{E}\\left[\\left(\\hat b - b\\right)^2\\right] - \\left(\\textrm{E}\\left[\\hat b - b\\right]\\right)^2\\\\\n\\textrm{Var}\\left[\\hat b\\right] &= \\underbrace{\\textrm{E}\\left[\\left(\\hat b - b\\right)^2\\right]}_{\\textrm{MSE}} - \\underbrace{\\left(\\textrm{E}\\left[\\hat b\\right]-b\\right)^2}_{\\textrm{BIAS}^2}\\\\\n\\end{align}\\]\ny despejando, se tiene que:\n\\[\\underbrace{\\textrm{E}\\left[\\left(\\hat b - b\\right)^2\\right]}_{\\textrm{MSE}} = \\textrm{Var}\\left[\\hat b\\right] + \\underbrace{\\left(\\textrm{E}\\left[\\hat b\\right]-b\\right)^2}_{\\textrm{BIAS}^2}\\]"
  },
  {
    "objectID": "capitulos/nopara1.html#notación-o-y-o-de-landau",
    "href": "capitulos/nopara1.html#notación-o-y-o-de-landau",
    "title": "2  Capítulo 1 del curso",
    "section": "Notación \\(O\\) y \\(o\\) de Landau",
    "text": "Notación \\(O\\) y \\(o\\) de Landau\n\nNotación \\(O\\)\n\\(\\textrm{Big}-O\\) es una notación matemática para describir el comportamiento asintótico de una función, cuando su argumento tiende a un valor en particular o al infinito. Su uso en la computación es análogo, se usa para medir la complejidad de los algoritmos; es decir, la cantidad de operaciones que le toma a un algoritmo realizar internamente para arrojar el resultado final dada una entrada particular del algoritmo.\nPor ejemplo, cuando un algoritmo es \\(O\\left(n^2\\right)\\), se dice que es cuadrático en tiempo y se sabe que estaría en el orden de realizar \\(n^2\\) operaciones para procesar una entrada de tamaño \\(n\\).\nPara una función dada \\(g\\left(n\\right)\\), \\(O\\left(g\\left(n\\right)\\right)\\) se define como sigue:\n\\[O\\left(g\\left(n\\right)\\right) = \\left\\{f\\left(n\\right): \\textrm{existen constantes positivas} \\hspace{0.2cm} c \\hspace{0.2cm} \\textrm{y} \\hspace{0.2cm} n_0 \\hspace{0.2cm} \\textrm{tales que} \\hspace{0.2cm} 0 \\leq f\\left(n\\right) \\leq cg\\left(n\\right) \\hspace{0.2cm} \\forall \\hspace{0.2cm} n \\geq n_0 \\right\\}\\] Esto quiere decir que \\(O\\left(g\\left(n\\right)\\right)\\) es un conjunto de funciones que después de \\(n_0\\) son más pequeñas o a lo sumo iguales que \\(g\\left(n\\right)\\).\n\n\n\n\n\nEjemplo gráfico de la notación Big-O.\n\n\n\n\nEn este gráfico, \\(f\\left(n\\right)\\) es solo una de las posibles funciones que pertenecen al conjunto de funciones \\(O\\left(g\\left(n\\right)\\right)\\). Antes de \\(n_0\\), \\(f\\left(n\\right)\\) no siempre es más pequeña que \\(g\\left(n\\right)\\), pero después de \\(n_0\\) nunca sobrepasa a \\(g\\left(n\\right)\\).\n\nEl signo \\(\\left(=\\right)\\) en la expresión \\(f\\left(n\\right)=O\\left(g\\left(n\\right)\\right)\\) es una representación asintótica la cuál da a entender que cuando \\(n\\) se hace muy grande, \\(f\\left(n\\right)\\) y \\(g\\left(n\\right)\\) crecen a la misma velocidad.\n\nPor ejemplo, \\(3n^3=O\\left(n^3\\right)\\) mientras que \\(3n\\ne O\\left(n^3\\right)\\).\n\n\n\n\n\nEjemplo gráfico de la notación Big-O.\n\n\n\n\nPara verificar que \\(f\\left(n\\right) = O\\left(g\\left(n\\right)\\right)\\), debe existir al menor una constante \\(c\\) con la cuál se cumpla la siguiente desigualdad: \\[\\left|f\\left(n\\right)\\right|\\leq c\\left|g\\left(n\\right)\\right| \\hspace{0.2cm} \\forall \\hspace{0.2cm} n \\geq n_0.\\]\n\n\nNotación \\(o\\)\nLa notación \\(o\\) es usadapara denotar una cota superior que no es asintóticamente “ajustada”, o sea es estrictamente menor.\nPara una función dada \\(g\\left(n\\right)\\), \\(o\\left(g\\left(n\\right)\\right)\\) se define como sigue:\n\\[o\\left(g\\left(n\\right)\\right) = \\left\\{f\\left(n\\right): \\textrm{para cualquier constante postivia} \\hspace{0.2cm} c, \\hspace{0.2cm} \\textrm{existe una constante positiva} \\hspace{0.2cm} n_0 \\hspace{0.2cm} \\textrm{tal que} \\hspace{0.2cm} 0 \\leq f\\left(n\\right) &lt; cg\\left(n\\right) \\hspace{0.2cm} \\forall \\hspace{0.2cm} n \\geq n_0 \\right\\}\\] En esta definición, el conjunto de funciones \\(f\\left(n\\right)\\) son estrictamente más pequeñas que \\(cg\\left(n\\right)\\), por lo cuál la notación \\(o\\) es una cpta superior más fuerte que la notación \\(O\\).\n\nLa notaci;on \\(o\\) no permite que la función \\(f\\left(n\\right)\\) tenga la misma velocidad de crecimiento que \\(g\\left(n\\right)\\).\n\nEsto significa que a medida que \\(n\\) se hace grande, \\(f\\left(n\\right)\\) se vuelve insignificante respecto a \\(g\\left(n\\right)\\), es decir:\n\\[\\lim_{n \\to \\infty} \\frac{f\\left(n\\right)}{g\\left(n\\right)} = 0\\]\n\nEn la definición de la notación \\(o\\), la desigualdad debe cumplirse para cualquier constante \\(c\\), mientras que en la notación \\(O\\), es suficiente que algún \\(c\\) satisfaga la desigualdad.\nHaciendo una analogía con números reales \\(a\\) y \\(b\\) es algo así como: \\(f\\left(n\\right)=O\\left(g\\left(n\\right)\\right) \\approx a\\leq b\\) mientras que \\(f\\left(n\\right)=o\\left(g\\left(n\\right)\\right) \\approx a &lt; b\\)."
  },
  {
    "objectID": "capitulos/bd1.html",
    "href": "capitulos/bd1.html",
    "title": "3  Introducción",
    "section": "",
    "text": "Volver arriba"
  }
]